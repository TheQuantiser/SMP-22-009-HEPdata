{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb665ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import ROOT\n",
    "from hepdata_lib import Submission, Table, Variable, Uncertainty, RootFileReader\n",
    "\n",
    "\n",
    "\n",
    "ROOT_FILENAME = \"input/ZNuNuGPrePostFitPostFitEBEE.root\"\n",
    "OUTPUT_DIR = \"hepdata_output\"\n",
    "\n",
    "\n",
    "OBSERVABLE_NAME = r\"$p_{T}^{\\gamma}$\"\n",
    "OBSERVABLE_UNITS = \"GeV\"\n",
    "\n",
    "USE_GARWOOD = True\n",
    "POISSON_CL = 0.6827  # ~1 sigma\n",
    "\n",
    "CM_ENERGY_GEV = 13000.0  # 13 TeV\n",
    "PAPER_TITLE = (\n",
    "    \"Measurement of the $Z\\\\gamma$ production cross section and search for \"\n",
    "    \"anomalous neutral triple gauge couplings in pp collisions at $\\\\sqrt{s}=13$ TeV\"\n",
    ")\n",
    "CMS_ANALYSIS_ID = \"CMS SMP-22-009\"\n",
    "\n",
    "REGIONS = [\n",
    "    {\n",
    "        \"name\": \"Figure4_EB_pTgamma\",\n",
    "        \"location\": \"Figure 4 (left)\",\n",
    "        \"description\": (\n",
    "            \"Post-fit reconstruction-level photon transverse momentum $p_{T}^{\\\\gamma}$ \"\n",
    "            \"distribution in the ECAL barrel (EB) signal region for the full Run-2 CMS \"\n",
    "            \"dataset (138 fb$^{-1}$ at $\\\\sqrt{s}=13$ TeV). Black points labelled \"\n",
    "            \"'Observed' show the data with Poisson statistical uncertainties. The \"\n",
    "            \"background expectation is decomposed into the components listed as \"\n",
    "            \"dependent variables in this table. In the published figure, the \"\n",
    "            \"components labelled here as fiducial $Z\\\\gamma$, $W+\\\\gamma$, ECAL \"\n",
    "            \"spikes and misidentified electrons $e\\\\to\\\\gamma$ appear explicitly \"\n",
    "            \"in the legend. The components labelled here as jet fakes, \"\n",
    "            \"out-of-acceptance $Z(\\\\nu\\\\nu)\\\\gamma$ and minor backgrounds are \"\n",
    "            \"drawn in the stack but grouped together and shown as 'Other' in the \"\n",
    "            \"legend. The variable 'Total background' gives the sum of all non-signal \"\n",
    "            \"background components evaluated at their post-fit yields. The variable \"\n",
    "            \"'Predicted' gives the full post-fit model prediction (signal plus all \"\n",
    "            \"background components), with uncertainties propagated from the fit \"\n",
    "            \"covariance.\"\n",
    "        ),\n",
    "        \"root_dir\": \"postfit/EB_SR\",\n",
    "        \"data_hist\": \"data_obs\",\n",
    "        \"primary_mc\": [\n",
    "            (r\"Fiducial $Z\\gamma$\", \"mergedFiducialZNuNuG\"),\n",
    "            (r\"$W+\\gamma$\",         \"mergedWLNuG\"),\n",
    "            (\"Spikes\",              \"ECAL_spikes\"),\n",
    "            (r\"$e\\to\\gamma$\",       \"eleFakes\"),\n",
    "        ],\n",
    "        \"other_mc\": [\n",
    "            (\"Jet fakes\",                         \"jetFakes\"),\n",
    "            (r\"Out-of-acceptance $Z(\\nu\\nu)\\gamma$\", \"ooaFixed\"),\n",
    "            (\"Minor backgrounds\",                 \"minor_bkg\"),\n",
    "        ],\n",
    "        \"extra_mc\": [\n",
    "            (\"Total background\", \"TotalBkg\"),\n",
    "            (\"Predicted\",        \"TotalProcs\"),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Figure4_EE_pTgamma\",\n",
    "        \"location\": \"Figure 4 (right)\",\n",
    "        \"description\": (\n",
    "            \"Post-fit reconstruction-level photon transverse momentum $p_{T}^{\\\\gamma}$ \"\n",
    "            \"distribution in the ECAL endcap (EE) signal region for the full Run-2 CMS \"\n",
    "            \"dataset (138 fb$^{-1}$ at $\\\\sqrt{s}=13$ TeV). Black points labelled \"\n",
    "            \"'Observed' show the data with Poisson statistical uncertainties. The \"\n",
    "            \"background expectation is decomposed into the components listed as \"\n",
    "            \"dependent variables in this table. In the published figure, the \"\n",
    "            \"components labelled here as fiducial $Z\\\\gamma$, $W+\\\\gamma$, beam \"\n",
    "            \"halo and misidentified electrons $e\\\\to\\\\gamma$ appear explicitly \"\n",
    "            \"in the legend. The components labelled here as jet fakes, \"\n",
    "            \"out-of-acceptance $Z(\\\\nu\\\\nu)\\\\gamma$ and minor backgrounds are \"\n",
    "            \"drawn in the stack but grouped together and shown as 'Other' in the \"\n",
    "            \"legend. The variable 'Total background' gives the sum of all non-signal \"\n",
    "            \"background components evaluated at their post-fit yields. The variable \"\n",
    "            \"'Predicted' gives the full post-fit model prediction (signal plus all \"\n",
    "            \"background components), with uncertainties propagated from the fit \"\n",
    "            \"covariance.\"\n",
    "        ),\n",
    "        \"root_dir\": \"postfit/EE_SR\",\n",
    "        \"data_hist\": \"data_obs\",\n",
    "        \"primary_mc\": [\n",
    "            (r\"Fiducial $Z\\gamma$\", \"mergedFiducialZNuNuG\"),\n",
    "            (r\"$W+\\gamma$\",         \"mergedWLNuG\"),\n",
    "            (r\"$e\\to\\gamma$\",       \"eleFakes\"),\n",
    "            (\"Beam halo\",           \"beamHalo\"),\n",
    "        ],\n",
    "        \"other_mc\": [\n",
    "            (\"Jet fakes\",                         \"jetFakes\"),\n",
    "            (r\"Out-of-acceptance $Z(\\nu\\nu)\\gamma$\", \"OOAfixed\"),\n",
    "            (\"Minor backgrounds\",                 \"minor_bkg\"),\n",
    "        ],\n",
    "        \"extra_mc\": [\n",
    "            (\"Total background\", \"TotalBkg\"),\n",
    "            (\"Predicted\",        \"TotalProcs\"),\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def make_asym_variable(label, values, err_down, err_up, units=None, unc_name=\"total\"):\n",
    "    v = Variable(label, is_independent=False, is_binned=False, units=units)\n",
    "    v.values = values\n",
    "    unc = Uncertainty(unc_name, is_symmetric=False)\n",
    "    unc.values = [(-dn, +up) for dn, up in zip(err_down, err_up)]\n",
    "    v.add_uncertainty(unc)\n",
    "    return v\n",
    "\n",
    "def build_table3_fiducial_xs():\n",
    "    table = Table(\"Table3_FiducialCrossSections\")\n",
    "    table.location = \"Table 3\"\n",
    "    table.description = (\n",
    "        \"Measured and predicted fiducial cross sections (fb) in the barrel, endcaps, and combined phase space. \"\n",
    "        \"Predictions shown at NLO (MADGRAPH5_aMC@NLO) and NNLO (MATRIX).\"\n",
    "    )\n",
    "    table.keywords[\"cmenergies\"] = [CM_ENERGY_GEV]\n",
    "    table.keywords[\"reactions\"] = [\"P P --> Z GAMMA\"]\n",
    "    table.keywords[\"phrases\"] = [\"Fiducial cross section\"]\n",
    "\n",
    "    reg = Variable(\"Region\", is_independent=True, is_binned=False)\n",
    "    reg.values = [r\"Barrel ($|\\eta|<1.4442$)\",\n",
    "                  r\"Endcaps ($1.566<|\\eta|<2.5$)\",\n",
    "                  \"Total\"]\n",
    "    table.add_variable(reg)\n",
    "\n",
    "    table.add_variable(make_asym_variable(\n",
    "        \"Measured\", [16.7, 7.8, 23.3],\n",
    "        err_down=[1.0, 0.7, 1.3],\n",
    "        err_up  =[1.0, 0.8, 1.4],\n",
    "        units=\"fb\", unc_name=\"total\"\n",
    "    ))\n",
    "    table.add_variable(make_asym_variable(\n",
    "        r\"NLO (MADGRAPH5_aMC@NLO)\", [19.6, 6.4, 26.1],\n",
    "        err_down=[0.7, 0.3, 1.0],\n",
    "        err_up  =[0.7, 0.3, 1.0],\n",
    "        units=\"fb\", unc_name=\"theory\"\n",
    "    ))\n",
    "    table.add_variable(make_asym_variable(\n",
    "        r\"NNLO (MATRIX)\", [19.3, 6.21, 25.4],\n",
    "        err_down=[0.3, 0.09, 0.3],\n",
    "        err_up  =[0.3, 0.07, 0.4],\n",
    "        units=\"fb\", unc_name=\"theory\"\n",
    "    ))\n",
    "    return table\n",
    "\n",
    "\n",
    "def build_table4_xs_vs_ptgamma():\n",
    "    table = Table(\"Table4_CrossSectionVsPtGamma\")\n",
    "    table.location = \"Table 4\"\n",
    "    table.description = (\n",
    "        \"Measured and predicted cross sections (fb) in bins of photon transverse momentum.\"\n",
    "    )\n",
    "    table.keywords[\"cmenergies\"] = [CM_ENERGY_GEV]\n",
    "    table.keywords[\"reactions\"] = [\"P P --> Z GAMMA\"]\n",
    "    table.keywords[\"observables\"] = [\"SIG\"]\n",
    "    table.keywords[\"phrases\"] = [\"Binned cross section\"]\n",
    "\n",
    "    x = Variable(r\"$p_{T}^{\\gamma}$\", is_independent=True, is_binned=True, units=\"GeV\")\n",
    "    bins = [(225,275),(275,350),(350,450),(450,600),(600,800),(800,1500)]\n",
    "    x.values = bins\n",
    "    table.add_variable(x)\n",
    "\n",
    "    table.add_variable(make_asym_variable(\n",
    "        \"Measured\",\n",
    "        [12.45, 6.95, 2.61, 1.08, 0.282, 0.092],\n",
    "        err_down=[0.87, 0.57, 0.33, 0.20, 0.009, 0.005],\n",
    "        err_up  =[0.91, 0.60, 0.35, 0.21, 0.010, 0.005],\n",
    "        units=\"fb\", unc_name=\"total\"\n",
    "    ))\n",
    "    table.add_variable(make_asym_variable(\n",
    "        r\"NLO (MADGRAPH5_aMC@NLO)\",\n",
    "        [12.88, 8.14, 3.34, 1.26, 0.345, 0.107],\n",
    "        err_down=[0.49, 0.30, 0.11, 0.05, 0.019, 0.012],\n",
    "        err_up  =[0.42, 0.31, 0.17, 0.08, 0.026, 0.011],\n",
    "        units=\"fb\", unc_name=\"theory\"\n",
    "    ))\n",
    "    table.add_variable(make_asym_variable(\n",
    "        r\"NNLO (MATRIX)\",\n",
    "        [12.83, 7.89, 3.22, 1.22, 0.331, 0.091],\n",
    "        err_down=[0.15, 0.15, 0.06, 0.02, 0.005, 0.014],\n",
    "        err_up  =[0.17, 0.16, 0.07, 0.02, 0.007, 0.020],\n",
    "        units=\"fb\", unc_name=\"theory\"\n",
    "    ))\n",
    "    return table\n",
    "\n",
    "\n",
    "def build_table5_aNTGC_limits():\n",
    "    table = Table(\"Table5_aNTGC_95CL\")\n",
    "    table.location = \"Table 5\"\n",
    "    table.description = (\n",
    "        \"Expected and observed 95% CL intervals for anomalous coupling parameters, \"\n",
    "        \"with other parameters fixed to zero.\"\n",
    "    )\n",
    "    table.keywords[\"cmenergies\"] = [CM_ENERGY_GEV]\n",
    "    table.keywords[\"phrases\"] = [\"aNTGC\", \"95% CL\", \"Limits\"]\n",
    "\n",
    "    p = Variable(\"Parameter\", is_independent=True, is_binned=False)\n",
    "    p.values = [r\"$h_{3}^{\\gamma}\\times 10^{4}$\",\n",
    "                r\"$h_{4}^{\\gamma}\\times 10^{7}$\",\n",
    "                r\"$h_{3}^{Z}\\times 10^{4}$\",\n",
    "                r\"$h_{4}^{Z}\\times 10^{7}$\"]\n",
    "    table.add_variable(p)\n",
    "\n",
    "    exp_lo = Variable(\"Expected lower\", is_independent=False, is_binned=False)\n",
    "    exp_hi = Variable(\"Expected upper\", is_independent=False, is_binned=False)\n",
    "    obs_lo = Variable(\"Observed lower\", is_independent=False, is_binned=False)\n",
    "    obs_hi = Variable(\"Observed upper\", is_independent=False, is_binned=False)\n",
    "\n",
    "    exp_lo.values = [-2.8, -5.9, -1.8, -3.7]\n",
    "    exp_hi.values = [ 2.9,  6.0,  1.9,  3.7]\n",
    "    obs_lo.values = [-3.4, -6.8, -2.2, -4.1]\n",
    "    obs_hi.values = [ 3.5,  6.8,  2.2,  4.2]\n",
    "\n",
    "    table.add_variable(exp_lo); table.add_variable(exp_hi)\n",
    "    table.add_variable(obs_lo); table.add_variable(obs_hi)\n",
    "    return table\n",
    "\n",
    "def poisson_garwood_intervals(values, cl=POISSON_CL):\n",
    "    alpha = 1.0 - cl\n",
    "    err_down, err_up = [], []\n",
    "    for y in values:\n",
    "        n = float(y)\n",
    "        if n < 0:\n",
    "            raise ValueError(f\"Negative data bin content: {n}\")\n",
    "        if n == 0.0:\n",
    "            low = 0.0\n",
    "        else:\n",
    "            low = 0.5 * ROOT.Math.chisquared_quantile(alpha / 2.0, 2.0 * n)\n",
    "        up = 0.5 * ROOT.Math.chisquared_quantile_c(alpha / 2.0, 2.0 * (n + 1.0))\n",
    "        err_down.append(n - low)\n",
    "        err_up.append(up - n)\n",
    "    return err_down, err_up\n",
    "\n",
    "\n",
    "def make_mc_variable(label, hist_dict):\n",
    "    v = Variable(label, is_independent=False, is_binned=False)\n",
    "    v.values = hist_dict[\"y\"]\n",
    "    dy = hist_dict.get(\"dy\")\n",
    "    if dy is not None:\n",
    "        if len(dy) > 0 and isinstance(dy[0], tuple):\n",
    "            unc = Uncertainty(\"stat+syst\", is_symmetric=False)\n",
    "            unc.values = dy\n",
    "        else:\n",
    "            unc = Uncertainty(\"stat+syst\", is_symmetric=True)\n",
    "            unc.values = dy\n",
    "        v.add_uncertainty(unc)\n",
    "    return v\n",
    "\n",
    "\n",
    "def make_data_variable(label, hist_dict):\n",
    "    y = hist_dict[\"y\"]\n",
    "    v = Variable(label, is_independent=False, is_binned=False)\n",
    "    v.values = y\n",
    "\n",
    "    if USE_GARWOOD:\n",
    "        err_down, err_up = poisson_garwood_intervals(y)\n",
    "        asym = [(-dn, +up) for dn, up in zip(err_down, err_up)]\n",
    "        unc = Uncertainty(\"stat\", is_symmetric=False)\n",
    "        unc.values = asym\n",
    "    else:\n",
    "        errs = [math.sqrt(val) if val >= 0.0 else 0.0 for val in y]\n",
    "        unc = Uncertainty(\"stat\", is_symmetric=True)\n",
    "        unc.values = errs\n",
    "\n",
    "    v.add_uncertainty(unc)\n",
    "    return v\n",
    "\n",
    "\n",
    "def read_hist_1d(reader, dir_path, hist_name):\n",
    "    \"\"\"Robust path handling for ROOT histograms.\"\"\"\n",
    "    tried = []\n",
    "    path1 = f\"{dir_path}/{hist_name}\" if dir_path else hist_name\n",
    "    tried.append(path1)\n",
    "    try:\n",
    "        return reader.read_hist_1d(path1)\n",
    "    except Exception:\n",
    "        if dir_path and \"/\" in dir_path:\n",
    "            tail = dir_path.split(\"/\", 1)[-1]\n",
    "            path2 = f\"{tail}/{hist_name}\"\n",
    "            tried.append(path2)\n",
    "            try:\n",
    "                return reader.read_hist_1d(path2)\n",
    "            except Exception as e2:\n",
    "                raise RuntimeError(\n",
    "                    f\"Could not find histogram '{hist_name}' in ROOT file. \"\n",
    "                    f\"Tried paths: {tried}\"\n",
    "                ) from e2\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                f\"Could not find histogram '{hist_name}' in ROOT file. \"\n",
    "                f\"Tried path: {tried[0]}\"\n",
    "            )\n",
    "\n",
    "def build_table_for_region(reader, cfg):\n",
    "    root_dir = cfg[\"root_dir\"]\n",
    "    data_dict = read_hist_1d(reader, root_dir, cfg[\"data_hist\"])\n",
    "\n",
    "    x_var = Variable(\n",
    "        OBSERVABLE_NAME,\n",
    "        is_independent=True,\n",
    "        is_binned=True,\n",
    "        units=OBSERVABLE_UNITS,\n",
    "    )\n",
    "    x_var.values = data_dict[\"x_edges\"]\n",
    "\n",
    "    table = Table(cfg[\"name\"])\n",
    "    table.location = cfg[\"location\"]\n",
    "    table.description = cfg[\"description\"]\n",
    "\n",
    "    # Keywords: common for both regions\n",
    "    table.keywords[\"cmenergies\"] = [CM_ENERGY_GEV]\n",
    "    table.keywords[\"reactions\"] = [\"P P --> Z GAMMA\"]\n",
    "    table.keywords[\"observables\"] = [\"DSIG/DPT\"]\n",
    "    table.keywords[\"phrases\"] = [\n",
    "        \"Differential cross section\",\n",
    "        \"Z to invisible\",\n",
    "        \"High-pt photon\",\n",
    "        \"Run 2\",\n",
    "    ]\n",
    "\n",
    "    table.add_variable(x_var)\n",
    "    table.add_variable(make_data_variable(\"Observed\", data_dict))\n",
    "\n",
    "    for label, hist_name in cfg.get(\"primary_mc\", []):\n",
    "        mc_dict = read_hist_1d(reader, root_dir, hist_name)\n",
    "        table.add_variable(make_mc_variable(label, mc_dict))\n",
    "\n",
    "    for label, hist_name in cfg.get(\"other_mc\", []):\n",
    "        mc_dict = read_hist_1d(reader, root_dir, hist_name)\n",
    "        table.add_variable(make_mc_variable(label, mc_dict))\n",
    "\n",
    "    for label, hist_name in cfg.get(\"extra_mc\", []):\n",
    "        extra_dict = read_hist_1d(reader, root_dir, hist_name)\n",
    "        table.add_variable(make_mc_variable(label, extra_dict))\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def build_submission():\n",
    "    sub = Submission()\n",
    "\n",
    "    # Short top-level description of the analysis\n",
    "    sub.comment = (\n",
    "        f\"{PAPER_TITLE}. CMS analysis {CMS_ANALYSIS_ID}. \"\n",
    "        \"Z→νν with an associated high-$p_{T}$ photon, using 138 fb$^{-1}$ \"\n",
    "        \"of pp collisions at $\\\\sqrt{s}=13$ TeV. \"\n",
    "        \"The tables in this submission provide the post-fit reconstruction-level \"\n",
    "        \"$p_{T}^{\\\\gamma}$ spectra in the EB and EE signal regions corresponding \"\n",
    "        \"to Figure 4 of the paper.\"\n",
    "    )\n",
    "\n",
    "    # Optional abstract file (if you provide one)\n",
    "    if ABSTRACT_FILE is not None and os.path.exists(ABSTRACT_FILE):\n",
    "        sub.read_abstract(ABSTRACT_FILE)\n",
    "\n",
    "    reader = RootFileReader(ROOT_FILENAME)\n",
    "    for cfg in REGIONS:\n",
    "        table = build_table_for_region(reader, cfg)\n",
    "        sub.add_table(table)\n",
    "\n",
    "    sub.add_table(build_table3_fiducial_xs())\n",
    "    sub.add_table(build_table4_xs_vs_ptgamma())\n",
    "    sub.add_table(build_table5_aNTGC_limits())\n",
    "\n",
    "\n",
    "    return sub\n",
    "\n",
    "\n",
    "def main():\n",
    "    sub = build_submission()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    sub.create_files(OUTPUT_DIR)\n",
    "    print(f\"HEPData submission written to: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "\n",
    "def validate_hepdata_output(output_dir=OUTPUT_DIR):\n",
    "    try:\n",
    "        import yaml\n",
    "    except ImportError:\n",
    "        print(\"PyYAML is not available; cannot parse YAML for validation.\")\n",
    "        return\n",
    "\n",
    "    yaml_files = sorted(glob.glob(os.path.join(output_dir, \"*.yaml\")))\n",
    "    if not yaml_files:\n",
    "        print(f\"No YAML files found in {output_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nValidation of HEPData YAML files in: {output_dir}\")\n",
    "    for path in yaml_files:\n",
    "        with open(path, \"r\") as f:\n",
    "            docs = list(yaml.safe_load_all(f))\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        print(f\"\\n=== {fname} ===\")\n",
    "\n",
    "        # submission.yaml is a multi-document file with metadata + table refs\n",
    "        if fname == \"submission.yaml\":\n",
    "            print(f\"  {fname} contains {len(docs)} document(s).\")\n",
    "            for i, doc in enumerate(docs):\n",
    "                if doc is None:\n",
    "                    print(f\"    doc {i}: <empty>\")\n",
    "                    continue\n",
    "                keys = list(doc.keys())\n",
    "                print(f\"    doc {i}: keys = {keys}\")\n",
    "            continue\n",
    "\n",
    "        # table_X.yaml is normally a single document\n",
    "        if not docs:\n",
    "            print(\"  WARNING: empty YAML document.\")\n",
    "            continue\n",
    "\n",
    "        doc = docs[0]\n",
    "        if \"independent_variables\" not in doc or \"dependent_variables\" not in doc:\n",
    "            print(\"  Not a standard table document. Keys:\", list(doc.keys()))\n",
    "            continue\n",
    "\n",
    "        indep = doc[\"independent_variables\"]\n",
    "        dep = doc[\"dependent_variables\"]\n",
    "        print(f\"  independent_variables: {len(indep)}, dependent_variables: {len(dep)}\")\n",
    "\n",
    "        if not indep:\n",
    "            print(\"  WARNING: no independent variables found.\")\n",
    "            continue\n",
    "\n",
    "        n_bins = len(indep[0].get(\"values\", []))\n",
    "        print(f\"  number of bins (from first independent variable): {n_bins}\")\n",
    "\n",
    "        for dv in dep:\n",
    "            name = dv.get(\"header\", {}).get(\"name\", \"<unnamed>\")\n",
    "            n_vals = len(dv.get(\"values\", []))\n",
    "            status = \"OK\" if n_vals == n_bins else f\"MISMATCH ({n_vals} vs {n_bins})\"\n",
    "            print(f\"    {name}: {n_vals} values -> {status}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a1fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEPData submission written to: hepdata_output\n",
      "\n",
      "Validation of HEPData YAML files in: hepdata_output\n",
      "\n",
      "=== figure4_eb_ptgamma.yaml ===\n",
      "  independent_variables: 1, dependent_variables: 10\n",
      "  number of bins (from first independent variable): 11\n",
      "    Observed: 11 values -> OK\n",
      "    Fiducial $Z\\gamma$: 11 values -> OK\n",
      "    $W+\\gamma$: 11 values -> OK\n",
      "    Spikes: 11 values -> OK\n",
      "    $e\\to\\gamma$: 11 values -> OK\n",
      "    Jet fakes: 11 values -> OK\n",
      "    Out-of-acceptance $Z(\\nu\\nu)\\gamma$: 11 values -> OK\n",
      "    Minor backgrounds: 11 values -> OK\n",
      "    Total background: 11 values -> OK\n",
      "    Predicted: 11 values -> OK\n",
      "\n",
      "=== figure4_ee_ptgamma.yaml ===\n",
      "  independent_variables: 1, dependent_variables: 10\n",
      "  number of bins (from first independent variable): 7\n",
      "    Observed: 7 values -> OK\n",
      "    Fiducial $Z\\gamma$: 7 values -> OK\n",
      "    $W+\\gamma$: 7 values -> OK\n",
      "    $e\\to\\gamma$: 7 values -> OK\n",
      "    Beam halo: 7 values -> OK\n",
      "    Jet fakes: 7 values -> OK\n",
      "    Out-of-acceptance $Z(\\nu\\nu)\\gamma$: 7 values -> OK\n",
      "    Minor backgrounds: 7 values -> OK\n",
      "    Total background: 7 values -> OK\n",
      "    Predicted: 7 values -> OK\n",
      "\n",
      "=== submission.yaml ===\n",
      "  submission.yaml contains 6 document(s).\n",
      "    doc 0: keys = ['additional_resources', 'comment', 'data_license']\n",
      "    doc 1: keys = ['data_file', 'description', 'keywords', 'location', 'name']\n",
      "    doc 2: keys = ['data_file', 'description', 'keywords', 'location', 'name']\n",
      "    doc 3: keys = ['data_file', 'description', 'keywords', 'location', 'name']\n",
      "    doc 4: keys = ['data_file', 'description', 'keywords', 'location', 'name']\n",
      "    doc 5: keys = ['data_file', 'description', 'keywords', 'location', 'name']\n",
      "\n",
      "=== table3_fiducialcrosssections.yaml ===\n",
      "  independent_variables: 1, dependent_variables: 3\n",
      "  number of bins (from first independent variable): 3\n",
      "    Measured: 3 values -> OK\n",
      "    NLO (MADGRAPH5_aMC@NLO): 3 values -> OK\n",
      "    NNLO (MATRIX): 3 values -> OK\n",
      "\n",
      "=== table4_crosssectionvsptgamma.yaml ===\n",
      "  independent_variables: 1, dependent_variables: 3\n",
      "  number of bins (from first independent variable): 6\n",
      "    Measured: 6 values -> OK\n",
      "    NLO (MADGRAPH5_aMC@NLO): 6 values -> OK\n",
      "    NNLO (MATRIX): 6 values -> OK\n",
      "\n",
      "=== table5_antgc_95cl.yaml ===\n",
      "  independent_variables: 1, dependent_variables: 4\n",
      "  number of bins (from first independent variable): 4\n",
      "    Expected lower: 4 values -> OK\n",
      "    Expected upper: 4 values -> OK\n",
      "    Observed lower: 4 values -> OK\n",
      "    Observed upper: 4 values -> OK\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "validate_hepdata_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f6ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "combine-634",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
